{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module to apply various Feature Selection Algorithms to get a subset of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mifs as mf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = pd.read_csv('Features/Normalizedfeatures.csv', index_col=-1).values\n",
    "Y = pd.read_csv('Features/Normalizedfeatures.csv', index_col=0).values\n",
    "yy = Y[:,119]\n",
    "\n",
    "yy = [int(i-2) if i == 2 else int(i) for i in yy]\n",
    "\n",
    "yy = np.array(yy)\n",
    "yy = np.transpose(yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Mutual Information based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto selected feature #1 : 23, JMIM: 0.0951485653024\n",
      "Auto selected feature #2 : 13, JMIM: 0.108607729154\n",
      "Auto selected feature #3 : 97, JMIM: 0.0781291254979\n",
      "Auto selected feature #4 : 94, JMIM: 0.0730138886444\n",
      "Auto selected feature #5 : 109, JMIM: 0.0686546497634\n",
      "Auto selected feature #6 : 96, JMIM: 0.0564151292179\n",
      "Auto selected feature #7 : 98, JMIM: 0.0465382944167\n",
      "Auto selected feature #8 : 46, JMIM: 0.0435559731003\n",
      "Auto selected feature #9 : 100, JMIM: 0.0427583436875\n",
      "Auto selected feature #10 : 85, JMIM: 0.0427583436875\n",
      "Auto selected feature #11 : 42, JMIM: 0.0427583436875\n",
      "Auto selected feature #12 : 82, JMIM: 0.0333094531806\n",
      "Auto selected feature #13 : 107, JMIM: 0.0324904154395\n",
      "Auto selected feature #14 : 39, JMIM: 0.0324904154395\n",
      "Auto selected feature #15 : 31, JMIM: 0.0324904154395\n",
      "Auto selected feature #16 : 25, JMIM: 0.0324904154395\n",
      "Auto selected feature #17 : 81, JMIM: 0.0324904154395\n"
     ]
    }
   ],
   "source": [
    "feat_selector = mf.MutualInformationFeatureSelector(method = 'JMI',verbose = 2)\n",
    "\n",
    "feat_selector.fit(X, yy)\n",
    "\n",
    "feat_selector.support_\n",
    "\n",
    "feat_selector.ranking_\n",
    "\n",
    "X_filtered1 = feat_selector.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Mutual Information Maximisation based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto selected feature #1 : 23, JMIM: 0.0951485653024\n",
      "Auto selected feature #2 : 13, JMIM: 0.108607729154\n",
      "Auto selected feature #3 : 97, JMIM: 0.0781291254979\n",
      "Auto selected feature #4 : 94, JMIM: 0.0730138886444\n",
      "Auto selected feature #5 : 109, JMIM: 0.0686546497634\n",
      "Auto selected feature #6 : 96, JMIM: 0.0564151292179\n",
      "Auto selected feature #7 : 42, JMIM: 0.0465382944167\n",
      "Auto selected feature #8 : 98, JMIM: 0.0457707965355\n",
      "Auto selected feature #9 : 99, JMIM: 0.0427583436875\n",
      "Auto selected feature #10 : 43, JMIM: 0.0372423706115\n",
      "Auto selected feature #11 : 49, JMIM: 0.0357415599464\n",
      "Auto selected feature #12 : 85, JMIM: 0.0353097930007\n",
      "Auto selected feature #13 : 46, JMIM: 0.0343756219597\n",
      "Auto selected feature #14 : 82, JMIM: 0.0333094531806\n",
      "Auto selected feature #15 : 81, JMIM: 0.032438807453\n",
      "Auto selected feature #16 : 33, JMIM: 0.0291297521426\n",
      "Auto selected feature #17 : 39, JMIM: 0.028232584626\n",
      "Auto selected feature #18 : 100, JMIM: 0.0281976252116\n",
      "Auto selected feature #19 : 17, JMIM: 0.026371068125\n",
      "Auto selected feature #20 : 106, JMIM: 0.0260586242893\n",
      "Auto selected feature #21 : 84, JMIM: 0.024832205389\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feat_selector = mf.MutualInformationFeatureSelector(method = 'JMIM',verbose = 2)\n",
    "\n",
    "feat_selector.fit(X, yy)\n",
    "\n",
    "feat_selector.support_\n",
    "\n",
    "feat_selector.ranking_\n",
    "\n",
    "X_filtered2 = feat_selector.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max-Relevance Min-Redundancy based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto selected feature #1 : 23, JMIM: 0.0951485653024\n",
      "Auto selected feature #2 : 58, JMIM: 5.05890944423\n",
      "Auto selected feature #3 : 55, JMIM: 0.739005868241\n",
      "Auto selected feature #4 : 6, JMIM: 0.739005868241\n",
      "Auto selected feature #5 : 34, JMIM: 0.501229656679\n",
      "Auto selected feature #6 : 109, JMIM: 0.308258717542\n",
      "Auto selected feature #7 : 36, JMIM: 0.308258717542\n",
      "Auto selected feature #8 : 67, JMIM: 0.308258717542\n",
      "Auto selected feature #9 : 25, JMIM: 0.308258717542\n",
      "Auto selected feature #10 : 77, JMIM: 0.308258717542\n",
      "Auto selected feature #11 : 29, JMIM: 0.308258717542\n",
      "Auto selected feature #12 : 54, JMIM: 0.153137070282\n",
      "Auto selected feature #13 : 79, JMIM: 0.153137070282\n",
      "Auto selected feature #14 : 69, JMIM: 0.0717785403301\n",
      "Auto selected feature #15 : 30, JMIM: 0.0717785403301\n",
      "Auto selected feature #16 : 60, JMIM: 0.0717785403301\n",
      "Auto selected feature #17 : 43, JMIM: 0.0717785403301\n",
      "Auto selected feature #18 : 45, JMIM: 0.0717785403301\n",
      "Auto selected feature #19 : 116, JMIM: 0.0672684842143\n",
      "Auto selected feature #20 : 32, JMIM: 0.0569724868385\n"
     ]
    }
   ],
   "source": [
    "feat_selector = mf.MutualInformationFeatureSelector(method = 'MRMR',verbose = 2)\n",
    "\n",
    "feat_selector.fit(X, yy)\n",
    "\n",
    "feat_selector.support_\n",
    "\n",
    "feat_selector.ranking_\n",
    "\n",
    "X_filtered3 = feat_selector.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Norm based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, yy)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_filtered4 = model.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, yy)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_filtered5 = model.transform(X)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of motor Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6071428571428571"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered5, yy, test_size=0.25, random_state=40)\n",
    "\n",
    "modelDecisionTree = tree.DecisionTreeClassifier()\n",
    "modelDecisionTree = modelDecisionTree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_test_pred = modelDecisionTree.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stocastic Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65714285714285714"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered5, yy , test_size=0.25, random_state=40)\n",
    "\n",
    "modelSGD = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "modelSGD.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = modelSGD.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68571428571428572"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered5, yy, test_size=0.25, random_state=40)\n",
    "\n",
    "modelSVM = svm.SVC()\n",
    "modelSVM.fit(X_train,y_train)\n",
    "\n",
    "y_test_pred = modelSVM.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69285714285714284"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered5, yy, test_size=0.25, random_state=40)\n",
    "modelSVM = svm.NuSVC()\n",
    "modelSVM.fit(X_train,y_train)\n",
    "\n",
    "y_test_pred = modelSVM.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65714285714285714"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered1, yy, test_size=0.25, random_state=40)\n",
    "modelSVM = svm.LinearSVC()\n",
    "modelSVM.fit(X_train,y_train)\n",
    "\n",
    "y_test_pred = modelSVM.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66459875435207494"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "modelRF = RandomForestClassifier(n_estimators=5, max_depth=None,min_samples_split=3, random_state=10)\n",
    "scores = cross_val_score(modelRF, X_filtered5, yy)\n",
    "scores.mean()                             \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65206332777490272"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "modelET = ExtraTreesClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(modelET, X_filtered5, yy)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68280947844515205"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "modelAda = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(modelAda,X_filtered5,yy)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Tree Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66428571428571426"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered5, yy, test_size=0.25, random_state=40)\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Class AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6785714285714286"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered1, yy, test_size=0.25, random_state=40)\n",
    "\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "\n",
    "bdt.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = bdt.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68571428571428572"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered5, yy, test_size=0.25, random_state=40)\n",
    "\n",
    "modelMLP = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "modelMLP.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = modelMLP.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6428571428571429"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.lda import LDA\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered1,yy, test_size=0.25, random_state=40)\n",
    "\n",
    "modelLDA = LDA()\n",
    "\n",
    "modelLDA.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = modelLDA.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
